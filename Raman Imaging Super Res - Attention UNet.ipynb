{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "mount_file_id": "1GHdCjqh84Xexa4GTzb8qntXQ08wgcIgd",
      "authorship_tag": "ABX9TyPSwqkJSmhp7TTtN4stU8kI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiverBotham/Raman/blob/main/Raman%20Imaging%20Super%20Res%20-%20Attention%20UNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO:\n",
        "\n",
        "\n",
        "*   Add utilities to github\n",
        "*   Update this notebook to clone repo\n",
        "*   Add updates to this notbook to run a train & test for de-noising using images from google drive but utilities from github\n",
        "*   Add in k-means & testing framework\n",
        "*   Repeat with second notebook for hyper-spectral super sesolution\n",
        "\n"
      ],
      "metadata": {
        "id": "D077tOtY-b6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To save forst clone the repo\n",
        "!git config --global user.name \"RiverBotham\"\n",
        "!git config --global user.email \"river.botham@gmail.com\"\n",
        "!git config --global user.password \"MY_PASSWORD\"\n",
        "\n",
        "token = 'MY_TOKEN'\n",
        "username = 'RiverBotham'\n",
        "repo = 'Raman'\n",
        "\n",
        "!git clone https://{token}@github.com/{username}/{repo}"
      ],
      "metadata": {
        "id": "q-lUBSc7BMNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd991d3-a652-42a9-cd8b-8f64b7ad8062"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Raman'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 148 (delta 46), reused 35 (delta 35), pack-reused 96 (from 1)\u001b[K\n",
            "Receiving objects: 100% (148/148), 7.52 MiB | 13.44 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move into the cloned repo, then File -> Save copy in GitHub\n",
        "%cd {repo}/Denoising"
      ],
      "metadata": {
        "id": "zzLakAJlDBnY",
        "outputId": "d8dc7e55-1420-4b39-c22a-d6024777ca8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Raman/Denoising\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "import shutil\n",
        "import argparse\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "import scipy.signal\n",
        "import math\n",
        "from skimage.metrics import structural_similarity as sk_ssim\n",
        "from sklearn.model_selection import KFold\n",
        "from skimage.transform import resize\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.distributed as dist\n",
        "import torch.utils.data.distributed\n",
        "import torch.multiprocessing as mp\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# import model, dataset, utilities"
      ],
      "metadata": {
        "id": "KWeXO7nYDF8j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "\n",
        "\n",
        "class ChannelAttentionBlock(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(ChannelAttentionBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.chan_attn = nn.Sequential(\n",
        "                nn.Conv2d(channels, channels // reduction, 1, padding=0, bias=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(channels // reduction, channels, 1, padding=0, bias=True),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.chan_attn(y)\n",
        "        return x * y\n",
        "\n",
        "class ResidualChannelAttentionBlock(nn.Module):\n",
        "    def __init__(self, channels=500, kernel_size=3, reduction=16, bias=True, act=nn.ReLU(True)):\n",
        "        super(ResidualChannelAttentionBlock, self).__init__()\n",
        "        modules_body = []\n",
        "        for i in range(2):\n",
        "            modules_body.append(nn.Conv2d(channels, channels, kernel_size, padding=(kernel_size//2), bias=bias))\n",
        "            if i == 0: modules_body.append(act)\n",
        "        modules_body.append(ChannelAttentionBlock(channels, reduction))\n",
        "\n",
        "        self.body = nn.Sequential(*modules_body)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.body(x)\n",
        "        res += x\n",
        "        return res\n",
        "\n",
        "class ResidualGroup(nn.Module):\n",
        "    def __init__(self, channels=500, kernel_size=3, reduction=16, bias=True, act=nn.ReLU(True), n_resblocks=6):\n",
        "        super(ResidualGroup, self).__init__()\n",
        "        modules_body = []\n",
        "        modules_body = [ResidualChannelAttentionBlock(channels, kernel_size, reduction, bias=bias, act=nn.ReLU(True)) for _ in range(n_resblocks)]\n",
        "        modules_body.append(nn.Conv2d(channels, channels, kernel_size, padding=(kernel_size//2), bias=bias))\n",
        "\n",
        "        self.body = nn.Sequential(*modules_body)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.body(x)\n",
        "        res += x\n",
        "        return res\n",
        "\n",
        "class Upsampler(nn.Sequential):\n",
        "    def __init__(self, scale, channels, kernel_size, bn=False, act=False, bias=True):\n",
        "\n",
        "        m = []\n",
        "        if (scale & (scale - 1)) == 0:\n",
        "            for _ in range(int(math.log(scale, 2))):\n",
        "                conv = nn.Conv2d(channels, 4*channels, kernel_size, padding=(kernel_size//2), bias=bias)\n",
        "                m.append(conv)\n",
        "                m.append(nn.PixelShuffle(2))\n",
        "                if bn: m.append(nn.BatchNorm2d(channels))\n",
        "                if act: m.append(nn.ReLU(True))\n",
        "        elif scale == 3:\n",
        "            m.append(nn.Conv2d(channels, 9*channels, kernel_size, padding=(kernel_size//2), bias=bias))\n",
        "            m.append(nn.PixelShuffle(3))\n",
        "            if bn: m.append(nn.BatchNorm2d(channels))\n",
        "            if act: m.append(nn.ReLU(True))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        super(Upsampler, self).__init__(*m)\n",
        "\n",
        "class Hyperspectral_RCAN(nn.Module):\n",
        "    def __init__(self, spectrum_len, scale=4, kernel_size=3, reduction=16, bias=True, act=nn.ReLU(True), n_resblocks=16, n_resgroups=18):\n",
        "        super(Hyperspectral_RCAN, self).__init__()\n",
        "        modules_head1 = [Upsampler(scale, spectrum_len, kernel_size, act=False), nn.Conv2d(spectrum_len, spectrum_len, kernel_size, padding=(kernel_size//2), bias=bias)]\n",
        "        modules_head2 = [nn.Conv2d(spectrum_len, int(spectrum_len/2), kernel_size, padding=(kernel_size//2), bias=bias)]\n",
        "\n",
        "        modules_body = [ResidualGroup(int(spectrum_len/2), kernel_size, reduction, act, n_resblocks) for _ in range(n_resgroups)]\n",
        "        modules_body.append(nn.Conv2d(int(spectrum_len/2), int(spectrum_len/2), kernel_size, padding=(kernel_size//2), bias=bias))\n",
        "\n",
        "        modules_tail = [nn.Conv2d(int(spectrum_len/2), int(spectrum_len/2), kernel_size, padding=(kernel_size//2), bias=bias)]\n",
        "        modules_tail.append(nn.Conv2d(int(spectrum_len/2), spectrum_len, kernel_size, padding=(kernel_size//2), bias=bias))\n",
        "\n",
        "        self.head1 = nn.Sequential(*modules_head1)\n",
        "        self.head2 = nn.Sequential(*modules_head2)\n",
        "        self.body = nn.Sequential(*modules_body)\n",
        "        self.tail = nn.Sequential(*modules_tail)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.head1(x)\n",
        "        x1 = self.head2(x)\n",
        "\n",
        "        res1 = self.body(x1)\n",
        "        res1 += x1\n",
        "\n",
        "        res2 = self.tail(res1)\n",
        "        res2 += x\n",
        "\n",
        "        return res2"
      ],
      "metadata": {
        "id": "Mei5k_ff0fci"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction Module\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, in_channels=500, num_features=64):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, num_features, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.conv1(x))\n",
        "\n",
        "# Multi-Scale Convolutional Block\n",
        "class MultiScaleBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(MultiScaleBlock, self).__init__()\n",
        "        self.conv3x3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5x5 = nn.Conv2d(in_channels, out_channels, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv7x7 = nn.Conv2d(in_channels, out_channels, kernel_size=7, stride=1, padding=3)\n",
        "        self.merge_conv = nn.Conv2d(out_channels * 3, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.relu(self.conv3x3(x))\n",
        "        out2 = self.relu(self.conv5x5(x))\n",
        "        out3 = self.relu(self.conv7x7(x))\n",
        "        merged = torch.cat([out1, out2, out3], dim=1)\n",
        "        return self.relu(self.merge_conv(merged))\n",
        "\n",
        "# Channel Attention (Squeeze-and-Excitation Block)\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_channels, in_channels // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_channels // reduction, in_channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.global_avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "# Spatial Attention\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size=7, padding=3)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        combined = torch.cat([avg_out, max_out], dim=1)\n",
        "        attention_map = self.sigmoid(self.conv1(combined))\n",
        "        return x * attention_map\n",
        "\n",
        "# Upsampling Module\n",
        "class UpsampleBlock(nn.Module):\n",
        "    def __init__(self, in_channels, scale_factor=2):\n",
        "        super(UpsampleBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels * (scale_factor ** 2), kernel_size=3, stride=1, padding=1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.pixel_shuffle(self.conv(x)))\n",
        "\n",
        "# Overall Network Architecture\n",
        "class MSANet(nn.Module):\n",
        "    def __init__(self, in_channels=500, out_channels=500, num_features=64):\n",
        "        super(MSANet, self).__init__()\n",
        "\n",
        "        # Feature Extraction\n",
        "        self.feature_extractor = FeatureExtractor(in_channels, num_features)\n",
        "\n",
        "        # Multi-Scale Block\n",
        "        self.multi_scale_block = MultiScaleBlock(num_features, num_features)\n",
        "\n",
        "        # Attention Blocks\n",
        "        self.channel_attention = ChannelAttention(num_features)\n",
        "        self.spatial_attention = SpatialAttention()\n",
        "\n",
        "        # Upsample 2x + 2x = 4x\n",
        "        self.upsample1 = UpsampleBlock(num_features, scale_factor=2)\n",
        "        self.upsample2 = UpsampleBlock(num_features, scale_factor=2)\n",
        "\n",
        "        # Reconstruction to match 500 channels output\n",
        "        self.reconstruction = nn.Conv2d(num_features, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Feature Extraction\n",
        "        x = self.feature_extractor(x)\n",
        "\n",
        "        # Multi-Scale Processing\n",
        "        x = self.multi_scale_block(x)\n",
        "\n",
        "        # Attention Mechanisms\n",
        "        x = self.channel_attention(x)\n",
        "        x = self.spatial_attention(x)\n",
        "\n",
        "        # Upsampling\n",
        "        x = self.upsample1(x)\n",
        "        x = self.upsample2(x)\n",
        "\n",
        "        # Reconstruction\n",
        "        out = self.reconstruction(x)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "2MLrSDOGx0up"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data set\n",
        "\n",
        "\n",
        "class RamanImageDataset(Dataset):\n",
        "    def __init__(self, image_ids, path, batch_size=2, hr_image_size=64, lr_image_size=16, spectrum_len=500,\n",
        "                spectrum_shift = 0., spectrum_flip = False, horizontal_flip = False, vertical_flip = False,\n",
        "                 rotate = False, patch = False, mixup = False):\n",
        "        self.image_ids = image_ids\n",
        "        self.path = path\n",
        "        self.batch_size = batch_size\n",
        "        self.hr_image_size = hr_image_size\n",
        "        self.lr_image_size = lr_image_size\n",
        "        self.spectrum_len = spectrum_len\n",
        "        self.spectrum_shift = spectrum_shift\n",
        "        self.spectrum_flip = spectrum_flip\n",
        "        self.horizontal_flip = horizontal_flip\n",
        "        self.vertical_flip = vertical_flip\n",
        "        self.rotate = rotate\n",
        "        self.patch = patch\n",
        "        self.mixup = mixup\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def load_image(self, id_name):\n",
        "        input_path =self.path + id_name + \".mat\"\n",
        "\n",
        "        output_data = scipy.io.loadmat(input_path)\n",
        "        output_values = list(output_data.values())\n",
        "        output_image = output_values[3]\n",
        "        return output_image\n",
        "\n",
        "    def pad_image(self, image, size, patch):\n",
        "        if image.shape[0] == size and image.shape[1] == size:\n",
        "            padded_image = image\n",
        "        elif image.shape[0] > size and image.shape[1] > size:\n",
        "            if patch:\n",
        "                padded_image = self.get_image_patch(image, size)\n",
        "            else:\n",
        "                padded_image = self.center_crop_image(image, size)\n",
        "        else:\n",
        "            padded_image = image\n",
        "            if padded_image.shape[0] > size:\n",
        "                if patch:\n",
        "                    padded_image = self.get_image_patch(padded_image, size)\n",
        "                else:\n",
        "                    padded_image = self.center_crop_image(padded_image, size)\n",
        "            else:\n",
        "                pad_before = int(np.floor((size - padded_image.shape[0])/2))\n",
        "                pad_after = int(np.ceil((size - padded_image.shape[0])/2))\n",
        "                padded_image = np.pad(padded_image, ((pad_before, pad_after), (0,0), (0, 0)), 'reflect')\n",
        "\n",
        "            if padded_image.shape[1] > size:\n",
        "                if patch:\n",
        "                    padded_image = self.get_image_patch(padded_image, size)\n",
        "                else:\n",
        "                    padded_image = self.center_crop_image(padded_image, size)\n",
        "            else:\n",
        "                pad_before = int(np.floor((size - padded_image.shape[1])/2))\n",
        "                pad_after = int(np.ceil((size - padded_image.shape[1])/2))\n",
        "                padded_image = np.pad(padded_image, ((0,0), (pad_before, pad_after), (0, 0)), 'reflect')\n",
        "\n",
        "        return padded_image\n",
        "\n",
        "    def get_image_patch(self, image, patch_size):\n",
        "        if image.shape[0] > patch_size:\n",
        "            start_idx_x = int(np.round(np.random.random() * (image.shape[0]-patch_size)))\n",
        "            end_idx_x = start_idx_x + patch_size\n",
        "        else:\n",
        "            start_idx_x = 0\n",
        "            end_idx_x = image.shape[0]\n",
        "\n",
        "        if image.shape[1] > patch_size:\n",
        "            start_idx_y = int(np.round(np.random.random() * (image.shape[1]-patch_size)))\n",
        "            end_idx_y = start_idx_y + patch_size\n",
        "        else:\n",
        "            start_idx_y = 0\n",
        "            end_idx_y = image.shape[1]\n",
        "\n",
        "        image_patch = image[start_idx_x:end_idx_x,start_idx_y:end_idx_y,:]\n",
        "        return image_patch\n",
        "\n",
        "    def center_crop_image(self, image, image_size):\n",
        "        cropped_image = image\n",
        "        if image.shape[0] > image_size:\n",
        "            dif = int(np.floor((image.shape[0] - image_size)/2))\n",
        "            cropped_image = cropped_image[dif:image_size+dif,:,:]\n",
        "\n",
        "        if image.shape[1] > image_size:\n",
        "            dif = int(np.floor((image.shape[1] - image_size)/2))\n",
        "            cropped_image = cropped_image[:,dif:image_size+dif,:]\n",
        "        return cropped_image\n",
        "\n",
        "    def flip_axis(self, image, axis):\n",
        "        if np.random.random() < 0.5:\n",
        "            image = np.asarray(image).swapaxes(axis, 0)\n",
        "            image = image[::-1, ...]\n",
        "            image = image.swapaxes(0, axis)\n",
        "        return image\n",
        "\n",
        "    def rotate_spectral_image(self, image):\n",
        "        rotation_extent = np.random.random()\n",
        "        if rotation_extent < 0.25:\n",
        "            rotation = 1\n",
        "        elif rotation_extent < 0.5:\n",
        "            rotation = 2\n",
        "        elif rotation_extent < 0.75:\n",
        "            rotation = 3\n",
        "        else:\n",
        "            rotation = 0\n",
        "        image = np.rot90(image, rotation)\n",
        "        return image\n",
        "\n",
        "    def shift_spectrum(self, image, shift_range):\n",
        "        shifted_spectrum_image = image\n",
        "        spectrum_shift_range = int(np.round(shift_range*image.shape[2]))\n",
        "        if spectrum_shift_range > 0:\n",
        "            shifted_spectrum_image = np.pad(image[:,:,spectrum_shift_range:], ((0,0), (0,0), (0,abs(spectrum_shift_range))), 'reflect')\n",
        "        elif spectrum_shift_range < 0:\n",
        "            shifted_spectrum_image = np.pad(image[:,:,:spectrum_shift_range], ((0,0), (0,0), (abs(spectrum_shift_range), 0)), 'reflect')\n",
        "        return shifted_spectrum_image\n",
        "\n",
        "    def spectrum_padding(self, image, spectrum_length):\n",
        "        if image.shape[-1] == spectrum_length:\n",
        "            padded_spectrum_image = image\n",
        "        elif image.shape[-1] > spectrum_length:\n",
        "            padded_spectrum_image = image[:,:,0:spectrum_length]\n",
        "        else:\n",
        "            padded_spectrum_image = np.pad(image, ((0,0), (0,0), (0, spectrum_length - image.shape[-1])), 'reflect')\n",
        "        return padded_spectrum_image\n",
        "\n",
        "    def image_mixup(self, image1, image2, alpha):\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "        image = (lam * image1) + ((1 - lam) * image2)\n",
        "        return image\n",
        "\n",
        "    def normalise_image(self, image):\n",
        "        image_max = np.tile(np.amax(image),image.shape)\n",
        "        normalised_image = np.divide(image,image_max)\n",
        "        return normalised_image\n",
        "\n",
        "    def downsample_image(self, image, scale = 4):\n",
        "        if scale >= 4:\n",
        "            start_idx = np.random.randint(1,scale-1)\n",
        "        else:\n",
        "            start_idx = 1\n",
        "        downsampled_image = image[start_idx::scale,start_idx::scale,:]\n",
        "        return downsampled_image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_size_ratio = self.hr_image_size // self.lr_image_size\n",
        "\n",
        "        outputimg = self.load_image(self.image_ids[idx])\n",
        "\n",
        "        mixup_on = False\n",
        "        if self.mixup:\n",
        "            if np.random.random() < 0.5:\n",
        "                image_idx = int(np.round(np.random.random() * (len(self.image_ids)-1)))\n",
        "                image2 = self.load_image(self.image_ids[image_idx])\n",
        "                mixup_on = True\n",
        "\n",
        "        # --------------- Image Data Augmentations ---------------\n",
        "        outputimg = self.pad_image(outputimg, self.hr_image_size, self.patch)\n",
        "        if mixup_on:\n",
        "            image2 = self.pad_image(image2, self.hr_image_size, self.patch)\n",
        "\n",
        "        if self.horizontal_flip:\n",
        "            outputimg = self.flip_axis(outputimg, 1)\n",
        "            if mixup_on:\n",
        "                image2 = self.flip_axis(image2, 1)\n",
        "\n",
        "        if self.vertical_flip:\n",
        "            outputimg = self.flip_axis(outputimg, 0)\n",
        "            if mixup_on:\n",
        "                image2 = self.flip_axis(image2, 0)\n",
        "\n",
        "        if self.rotate:\n",
        "            outputimg = self.rotate_spectral_image(outputimg)\n",
        "            if mixup_on:\n",
        "                image2 = self.rotate_spectral_image(image2)\n",
        "\n",
        "        # --------------- Spectral Data Augmentations ---------------\n",
        "        if self.spectrum_shift != 0.0:\n",
        "            shift_range = np.random.uniform(-self.spectrum_shift, self.spectrum_shift)\n",
        "            outputimg = self.shift_spectrum(outputimg, shift_range)\n",
        "            if mixup_on:\n",
        "                image2 = self.shift_spectrum(image2, shift_range)\n",
        "\n",
        "        outputimg = self.spectrum_padding(outputimg, self.spectrum_len)\n",
        "        if mixup_on:\n",
        "            image2 = self.spectrum_padding(image2, self.spectrum_len)\n",
        "\n",
        "        if self.spectrum_flip:\n",
        "            if np.random.random() < 0.5:\n",
        "                outputimg = self.flip_axis(outputimg, 2)\n",
        "                if mixup_on:\n",
        "                    image2 = self.flip_axis(image2, 2)\n",
        "\n",
        "        # --------------- Mixup ---------------\n",
        "        if mixup_on:\n",
        "            outputimg = self.image_mixup(outputimg, image2, 0.2)\n",
        "\n",
        "        # --------------- Normalisation and Downsampling ---------------\n",
        "        outputimg = self.normalise_image(outputimg)\n",
        "        inputimg = self.downsample_image(outputimg, image_size_ratio)\n",
        "\n",
        "        outputimg = np.moveaxis(outputimg, -1, 0)\n",
        "        inputimg = np.moveaxis(inputimg, -1, 0)\n",
        "\n",
        "        sample = {'input_image': inputimg, 'output_image': outputimg}\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)"
      ],
      "metadata": {
        "id": "w6PAklAu0hNJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utilities\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)"
      ],
      "metadata": {
        "id": "3NAulroG0i29"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "def train(dataloader, net, optimizer, scheduler, criterion, criterion_MSE, epoch, args):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    psnr = AverageMeter('PSNR', ':.4f')\n",
        "    ssim = AverageMeter('SSIM', ':.4f')\n",
        "    progress = ProgressMeter(len(dataloader), [batch_time, psnr, ssim], prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    scaler = GradScaler()  # For mixed precision training\n",
        "\n",
        "    end = time.time()\n",
        "    for i, data in enumerate(dataloader):\n",
        "        inputs = data['input_image'].float().cuda(args.gpu, non_blocking=True)\n",
        "        target = data['output_image'].float().cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Use autocast for mixed precision training\n",
        "        with autocast():\n",
        "            output = net(inputs)\n",
        "            # print(f\"target: {target.shape}\")\n",
        "            # print(f\"output: {output.shape}\")\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        # Scales the loss to prevent underflow in FP16 precision\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        if args.scheduler == \"cyclic-lr\" or args.scheduler == \"one-cycle-lr\":\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate other metrics without affecting backprop\n",
        "        with torch.no_grad():\n",
        "            loss_MSE = criterion_MSE(output, target)\n",
        "            losses.update(loss_MSE.item(), inputs.size(0))\n",
        "\n",
        "            psnr_batch = calc_psnr(output, target)\n",
        "            psnr.update(psnr_batch, inputs.size(0))\n",
        "\n",
        "            ssim_batch = calc_ssim(output, target)\n",
        "            ssim.update(ssim_batch, inputs.size(0))\n",
        "\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 20 == 0:\n",
        "            progress.display(i)\n",
        "\n",
        "    return losses.avg, psnr.avg, ssim.avg\n",
        "\n"
      ],
      "metadata": {
        "id": "smrIJIsQDp3c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(dataloader, net, criterion_MSE, args):\n",
        "\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    psnr = AverageMeter('PSNR', ':.4f')\n",
        "    ssim = AverageMeter('SSIM', ':.4f')\n",
        "    progress = ProgressMeter(len(dataloader), [batch_time, psnr, ssim], prefix='Validation: ')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for i, data in enumerate(dataloader):\n",
        "            inputs = data['input_image']\n",
        "            inputs = inputs.float()\n",
        "            inputs = inputs.cuda(args.gpu)\n",
        "            target = data['output_image']\n",
        "            target = target.float()\n",
        "            target = target.cuda(args.gpu)\n",
        "\n",
        "            output = net(inputs)\n",
        "\n",
        "            loss_MSE = criterion_MSE(output, target)\n",
        "            losses.update(loss_MSE.item(), inputs.size(0))\n",
        "\n",
        "            psnr_batch = calc_psnr(output, target)\n",
        "            psnr.update(psnr_batch, inputs.size(0))\n",
        "\n",
        "            ssim_batch = calc_ssim(output, target)\n",
        "            ssim.update(ssim_batch, inputs.size(0))\n",
        "\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % 20 == 0:\n",
        "                progress.display(i)\n",
        "\n",
        "    return losses.avg, psnr.avg, ssim.avg"
      ],
      "metadata": {
        "id": "ZvHvb_vkD2Wm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_noKmeans(args):\n",
        "    if args.seed is not None:\n",
        "        random.seed(args.seed)\n",
        "        torch.manual_seed(args.seed)\n",
        "        cudnn.deterministic = True\n",
        "\n",
        "    if args.dist_url == \"env://\" and args.world_size == -1:\n",
        "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "\n",
        "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
        "\n",
        "    ngpus_per_node = torch.cuda.device_count()\n",
        "\n",
        "    gpu = args.gpu\n",
        "\n",
        "    if args.gpu is not None:\n",
        "        print(\"Use GPU: {} for training\".format(args.gpu))\n",
        "\n",
        "    if args.distributed:\n",
        "        if args.dist_url == \"env://\" and args.rank == -1:\n",
        "            args.rank = int(os.environ[\"RANK\"])\n",
        "        if args.multiprocessing_distributed:\n",
        "            args.rank = args.rank * ngpus_per_node + gpu\n",
        "        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
        "                                world_size=args.world_size, rank=args.rank)\n",
        "\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    # Create model(s) and send to device(s)\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    scale = args.hr_image_size // args.lr_image_size\n",
        "    net = MSANet().float()\n",
        "\n",
        "    if args.distributed:\n",
        "        if args.gpu is not None:\n",
        "            torch.cuda.set_device(args.gpu)\n",
        "            args.batch_size = int(args.batch_size / ngpus_per_node)\n",
        "            args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)\n",
        "\n",
        "            net.cuda(args.gpu)\n",
        "            net = torch.nn.parallel.DistributedDataParallel(net, device_ids=[args.gpu])\n",
        "        else:\n",
        "            net.cuda(args.gpu)\n",
        "            net = torch.nn.parallel.DistributedDataParallel(net)\n",
        "    elif args.gpu is not None:\n",
        "        torch.cuda.set_device(args.gpu)\n",
        "        net.cuda(args.gpu)\n",
        "    else:\n",
        "        net = nn.DataParallel(net).cuda()\n",
        "\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    # Define dataset path and data splits\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    dataset_path = \"Dataset/\"\n",
        "    image_ids_csv = pd.read_csv(dataset_path + \"Image_IDs.csv\")\n",
        "\n",
        "    image_ids = image_ids_csv[\"id\"].values\n",
        "\n",
        "    train_split = round(0.85 * len(image_ids))\n",
        "    val_split = round(0.10 * len(image_ids))\n",
        "    test_split = round(0.05 * len(image_ids))\n",
        "    train_ids = image_ids[:train_split]\n",
        "    val_ids = image_ids[train_split:train_split+val_split]\n",
        "    test_ids = image_ids[train_split+val_split:]\n",
        "\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    # Create datasets and dataloaders\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    Raman_Dataset_Train = RamanImageDataset(train_ids, dataset_path, batch_size = args.batch_size,\n",
        "                                                    hr_image_size = args.hr_image_size, lr_image_size = args.lr_image_size,\n",
        "                                                    spectrum_len = args.spectrum_len, spectrum_shift = 0.1, spectrum_flip = True,\n",
        "                                                    horizontal_flip = True, vertical_flip = True, rotate = True, patch = True, mixup = True)\n",
        "\n",
        "    Raman_Dataset_Val = RamanImageDataset(val_ids, dataset_path, batch_size = args.batch_size,\n",
        "                                                    hr_image_size = args.hr_image_size, lr_image_size = args.lr_image_size,\n",
        "                                                    spectrum_len = args.spectrum_len)\n",
        "\n",
        "    train_loader = DataLoader(Raman_Dataset_Train, batch_size = args.batch_size, shuffle = False, num_workers = args.workers)\n",
        "    val_loader = DataLoader(Raman_Dataset_Val, batch_size = args.batch_size, shuffle = False, num_workers = args.workers)\n",
        "\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    # Define criterion(s), optimizer(s), and scheduler(s)\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "\n",
        "    # ------------Criterion------------\n",
        "    criterion = nn.L1Loss().cuda(args.gpu)\n",
        "    criterion_MSE = nn.MSELoss().cuda(args.gpu)\n",
        "\n",
        "    # ------------Optimizer------------\n",
        "    if args.optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(net.parameters(), lr = args.lr)\n",
        "    elif args.optimizer == \"adamW\":\n",
        "        optimizer = optim.AdamW(net.parameters(), lr = args.lr)\n",
        "    else: # Adam\n",
        "        optimizer = optim.Adam(net.parameters(), lr = args.lr)\n",
        "\n",
        "    # ------------Scheduler------------\n",
        "    if args.scheduler == \"decay-lr\":\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.2)\n",
        "    elif args.scheduler == \"multiplicative-lr\":\n",
        "        lmbda = lambda epoch: 0.985\n",
        "        scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
        "    elif args.scheduler == \"cyclic-lr\":\n",
        "        scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr = args.base_lr, max_lr = args.lr, mode = 'triangular2', cycle_momentum = False)\n",
        "    elif args.scheduler == \"one-cycle-lr\":\n",
        "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr = args.lr, steps_per_epoch=len(train_loader), epochs=args.epochs, cycle_momentum = False)\n",
        "    else: # constant-lr\n",
        "        scheduler = None\n",
        "\n",
        "    print('Started Training')\n",
        "    print('Training Details:')\n",
        "    print('Network:         {}'.format(args.network))\n",
        "    print('Epochs:          {}'.format(args.epochs))\n",
        "    print('Batch Size:      {}'.format(args.batch_size))\n",
        "    print('Optimizer:       {}'.format(args.optimizer))\n",
        "    print('Scheduler:       {}'.format(args.scheduler))\n",
        "    print('Learning Rate:   {}'.format(args.lr))\n",
        "    print('Spectrum Length: {}'.format(args.spectrum_len))\n",
        "\n",
        "    date = datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
        "    formatted_lr = '{:_.6f}'.format(float(args.lr)).rstrip('0').rstrip('.')\n",
        "\n",
        "    losses_dir = \"losses/{}_{}_{}_{}_{}_{}.csv\".format(date, args.optimizer, args.scheduler, formatted_lr, args.network, scale)\n",
        "    models_dir = \"{}_{}_{}_{}_{}_{}.pt\".format(date, args.optimizer, args.scheduler, formatted_lr, args.network, scale)\n",
        "    df = pd.DataFrame(columns=['epoch', 'train_loss', 'val_loss'])\n",
        "\n",
        "    # Early stopping\n",
        "    patience = args.patience if hasattr(args, 'patience') else 10  # Default patience of 10 epochs\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        train_loss, train_psnr, train_ssim = train(train_loader, net, optimizer, scheduler, criterion, criterion_MSE, epoch, args)\n",
        "        val_loss, valid_psnr, valid_ssim = validate(val_loader, net, criterion_MSE, args)\n",
        "        if args.scheduler != \"cyclic-lr\" and args.scheduler != \"one-cycle-lr\" and args.scheduler != \"constant-lr\":\n",
        "            scheduler.step()\n",
        "\n",
        "        print('Epoch {} done'.format(epoch))\n",
        "        print('Loss/train: {}'.format(train_loss))\n",
        "        print('Loss/val: {}'.format(val_loss))\n",
        "        print('PSNR/train: {}'.format(train_psnr))\n",
        "        print('PSNR/val: {}'.format(valid_psnr))\n",
        "        print('SSIM/train: {}'.format(train_ssim))\n",
        "        print('SSIM/val: {}'.format(valid_ssim))\n",
        "\n",
        "\n",
        "        new_row = pd.DataFrame({'epoch': [epoch], 'train_loss': [train_loss], 'val_loss': [val_loss]})\n",
        "\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "\n",
        "        # Early Stopping Logic\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(net.state_dict(), models_dir)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"Early stopping triggered. No improvement in validation loss for {patience} epochs. Finished at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    df.to_csv(losses_dir, index=False)\n",
        "    print('Finished Training')"
      ],
      "metadata": {
        "id": "SNYVMuYwCfwP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "qtYI_0qkGa3n",
        "outputId": "051ba6f0-2171-4b3b-e9b6-a9915e730e0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "O1sjKibTHrPN",
        "outputId": "75c0baf6-65ff-4de4-cbc7-73ed8987c1d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset.py  model.py  ResUNet.pt  utilities.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../.."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J1ZBnz0lm1w",
        "outputId": "7f8fa2c8-ebe8-4031-8e33-54c4d80444fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive/Colab\\ Notebooks/DeepeR-master/Hyperspectral Super-Resolution"
      ],
      "metadata": {
        "id": "RAHNfyHBGcGD",
        "outputId": "5eb91794-481a-42e7-c05c-0099a8da6145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/DeepeR-master/Hyperspectral Super-Resolution\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_psnr(output, target):\n",
        "    psnr = 0.\n",
        "    mse = nn.MSELoss()(output, target)\n",
        "    psnr = 10 * math.log10(torch.max(output)/mse)\n",
        "    return psnr\n",
        "\n",
        "def calc_ssim(output, target):\n",
        "    ssim = 0.\n",
        "    output = output.cpu().detach().numpy()\n",
        "    target = target.cpu().detach().numpy()\n",
        "\n",
        "    if output.ndim == 4:\n",
        "        for i in range(output.shape[0]):\n",
        "            output_i = np.squeeze(output[i,:,:,:])\n",
        "            output_i = np.moveaxis(output_i, 0, -1)\n",
        "            target_i = np.squeeze(target[i,:,:,:])\n",
        "            target_i = np.moveaxis(target_i, 0, -1)\n",
        "            batch_size = output.shape[0]\n",
        "            ssim += sk_ssim(output_i, target_i, data_range = output_i.max() - target_i.max(), multichannel=True)\n",
        "    else:\n",
        "        output_i = np.squeeze(output)\n",
        "        output_i = np.moveaxis(output_i, 0, -1)\n",
        "        target_i = np.squeeze(target)\n",
        "        target_i = np.moveaxis(target_i, 0, -1)\n",
        "        batch_size = 1\n",
        "        ssim += sk_ssim(output_i, target_i, data_range = output_i.max() - target_i.max(), multichannel=True)\n",
        "\n",
        "    ssim = ssim / batch_size\n",
        "    return ssim"
      ],
      "metadata": {
        "id": "6sQ6cib9zsW5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Default args from original code\n",
        "\n",
        "class Arguments:\n",
        "    pass\n",
        "\n",
        "args = Arguments()\n",
        "args.workers = 0\n",
        "args.epochs = 200\n",
        "args.start_epoch = 0\n",
        "args.batch_size = 3\n",
        "args.network = \"MSANet\"\n",
        "args.lam = 100\n",
        "args.optimizer = \"adamW\"\n",
        "args.lr = 1e-5\n",
        "args.base_lr = 1e-7\n",
        "args.scheduler = \"one-cycle-lr\"\n",
        "args.lr_image_size = 16\n",
        "args.hr_image_size = 64\n",
        "args.batch_norm = True\n",
        "args.spectrum_len = 500\n",
        "args.seed = None\n",
        "args.gpu = 0\n",
        "args.world_size = -1\n",
        "args.rank = -1\n",
        "args.dist_url = \"tcp://224.66.41.62:23456\"\n",
        "args.dist_backend = \"nccl\"\n",
        "args.multiprocessing_distributed = False\n",
        "args.patience = 10\n",
        "\n",
        "\n",
        "args.epochs=2\n",
        "train_noKmeans(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqEw59PrCzKG",
        "outputId": "1bfc272e-2210-4eb5-f6bd-480a76240363"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0 for training\n",
            "Started Training\n",
            "Training Details:\n",
            "Network:         MSANet\n",
            "Epochs:          2\n",
            "Batch Size:      3\n",
            "Optimizer:       adamW\n",
            "Scheduler:       one-cycle-lr\n",
            "Learning Rate:   1e-05\n",
            "Spectrum Length: 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-48836787ddcb>:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # For mixed precision training\n",
            "<ipython-input-8-48836787ddcb>:20: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 0/48]\tTime 23.020 (23.020)\tPSNR 16.1922 (16.1922)\tSSIM 0.0955 (0.0955)\n",
            "Epoch: [0][20/48]\tTime 15.156 (12.373)\tPSNR 12.2948 (14.5915)\tSSIM 0.0830 (0.0895)\n",
            "Epoch: [0][40/48]\tTime  8.406 (13.432)\tPSNR 12.1964 (14.6515)\tSSIM 0.0787 (0.1143)\n",
            "Validation: [0/6]\tTime 17.241 (17.241)\tPSNR 16.9823 (16.9823)\tSSIM 0.2123 (0.2123)\n",
            "Epoch 0 done\n",
            "Loss/train: 0.0026251979118872746\n",
            "Loss/val: 0.0015100069097517168\n",
            "PSNR/train: 14.765592317343739\n",
            "PSNR/val: 16.784348623372953\n",
            "SSIM/train: 0.12385315993247789\n",
            "SSIM/val: 0.2016629769080273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-a123733a263a>:148: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][ 0/48]\tTime  1.178 ( 1.178)\tPSNR 13.9771 (13.9771)\tSSIM 0.1056 (0.1056)\n",
            "Epoch: [1][20/48]\tTime  1.160 ( 1.496)\tPSNR 13.5096 (15.1351)\tSSIM 0.1543 (0.1557)\n",
            "Epoch: [1][40/48]\tTime  1.582 ( 1.699)\tPSNR 13.0313 (15.0301)\tSSIM 0.1542 (0.1699)\n",
            "Validation: [0/6]\tTime  1.583 ( 1.583)\tPSNR 17.1079 (17.1079)\tSSIM 0.2414 (0.2414)\n",
            "Epoch 1 done\n",
            "Loss/train: 0.0023108159536301778\n",
            "Loss/val: 0.0014454866622519843\n",
            "PSNR/train: 15.121128333497325\n",
            "PSNR/val: 16.9054404051279\n",
            "SSIM/train: 0.17471465575336353\n",
            "SSIM/val: 0.2308023726456992\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "emGdqQX0WqnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "def evaluate(dataloader, net, scale, args):\n",
        "\n",
        "    psnr = AverageMeter('PSNR', ':.4f')\n",
        "    ssim = AverageMeter('SSIM', ':.4f')\n",
        "    mse_NN = AverageMeter('MSE', ':.4f')\n",
        "    psnr_bicubic = AverageMeter('PSNR_Bicubic', ':.4f')\n",
        "    ssim_bicubic = AverageMeter('SSIM_Bicubic', ':.4f')\n",
        "    mse_bicubic = AverageMeter('MSE_Bicubic', ':.4f')\n",
        "    psnr_nearest_neighbours = AverageMeter('PSNR_Nearest_Neighbours', ':.4f')\n",
        "    ssim_nearest_neighbours = AverageMeter('SSIM_Nearest_Neighbours', ':.4f')\n",
        "    mse_nearest_neighbours = AverageMeter('MSE_Nearest_Neighbours', ':.4f')\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(dataloader):\n",
        "            # measure data loading time\n",
        "            x = data['input_image']\n",
        "            inputs = x.float()\n",
        "            inputs = inputs.cuda(args.gpu)\n",
        "            y = data['output_image']\n",
        "            target = y.float()\n",
        "            target = target.cuda(args.gpu)\n",
        "\n",
        "            # compute output\n",
        "            output = net(inputs)\n",
        "\n",
        "            x2 = np.squeeze(x.numpy())\n",
        "            y2 = np.squeeze(y.numpy())\n",
        "\n",
        "            nearest_neighbours = scipy.ndimage.zoom(x2,(1,scale,scale), order=0)\n",
        "            bicubic = scipy.ndimage.zoom(x2,(1,scale,scale), order=3)\n",
        "\n",
        "            bicubic = torch.from_numpy(bicubic)\n",
        "            bicubic = bicubic.cuda(args.gpu)\n",
        "\n",
        "            nearest_neighbours = torch.from_numpy(nearest_neighbours)\n",
        "            nearest_neighbours = nearest_neighbours.cuda(args.gpu)\n",
        "\n",
        "            # Nearest neighbours\n",
        "            psnr_batch_nearest_neighbours = calc_psnr(nearest_neighbours, target)\n",
        "            psnr_nearest_neighbours.update(psnr_batch_nearest_neighbours, inputs.size(0))\n",
        "\n",
        "            ssim_batch_nearest_neighbours = calc_ssim(nearest_neighbours, target)\n",
        "            ssim_nearest_neighbours.update(ssim_batch_nearest_neighbours, inputs.size(0))\n",
        "\n",
        "            mse_batch_nearest_neighbours = nn.MSELoss()(nearest_neighbours, target)\n",
        "            mse_nearest_neighbours.update(mse_batch_nearest_neighbours, inputs.size(0))\n",
        "\n",
        "            # Bicubic\n",
        "            psnr_batch_bicubic = calc_psnr(bicubic, target)\n",
        "            psnr_bicubic.update(psnr_batch_bicubic, inputs.size(0))\n",
        "\n",
        "            ssim_batch_bicubic = calc_ssim(bicubic, target)\n",
        "            ssim_bicubic.update(ssim_batch_bicubic, inputs.size(0))\n",
        "\n",
        "            mse_batch_bicubic = nn.MSELoss()(bicubic, target)\n",
        "            mse_bicubic.update(mse_batch_bicubic, inputs.size(0))\n",
        "\n",
        "            # Neural network\n",
        "            psnr_batch = calc_psnr(output, target)\n",
        "            psnr.update(psnr_batch, inputs.size(0))\n",
        "\n",
        "            ssim_batch = calc_ssim(output, target)\n",
        "            ssim.update(ssim_batch, inputs.size(0))\n",
        "\n",
        "            mse_batch = nn.MSELoss()(output, target)\n",
        "            mse_NN.update(mse_batch, inputs.size(0))\n",
        "\n",
        "    print(\"RCAN PSNR: {}    Bicubic PSNR: {}    Nearest Neighbours PSNR: {}\".format(psnr.avg, psnr_bicubic.avg, psnr_nearest_neighbours.avg))\n",
        "    print(\"RCAN SSIM: {}    Bicubic SSIM: {}    Nearest Neighbours SSIM: {}\".format(ssim.avg, ssim_bicubic.avg, ssim_nearest_neighbours.avg))\n",
        "    print(\"RCAN MSE:  {}    Bicubic MSE:  {}    Nearest Neighbours MSE:  {}\".format(mse_NN.avg, mse_bicubic.avg, mse_nearest_neighbours.avg))\n",
        "    return psnr.avg, psnr_bicubic.avg, psnr_nearest_neighbours.avg, ssim.avg, ssim_bicubic.avg, ssim_nearest_neighbours.avg, mse_NN.avg, mse_bicubic.avg, mse_nearest_neighbours.avg"
      ],
      "metadata": {
        "id": "8ujeP58VmTxM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_test(args):\n",
        "\n",
        "    if args.seed is not None:\n",
        "        random.seed(args.seed)\n",
        "        torch.manual_seed(args.seed)\n",
        "        cudnn.deterministic = True\n",
        "\n",
        "    if args.dist_url == \"env://\" and args.world_size == -1:\n",
        "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "\n",
        "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
        "\n",
        "    ngpus_per_node = torch.cuda.device_count()\n",
        "\n",
        "    gpu = args.gpu\n",
        "\n",
        "    if args.gpu is not None:\n",
        "        print(\"Use GPU: {} for testing\".format(args.gpu))\n",
        "\n",
        "    if args.distributed:\n",
        "        if args.dist_url == \"env://\" and args.rank == -1:\n",
        "            args.rank = int(os.environ[\"RANK\"])\n",
        "        if args.multiprocessing_distributed:\n",
        "            args.rank = args.rank * ngpus_per_node + gpu\n",
        "        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
        "                                world_size=args.world_size, rank=args.rank)\n",
        "\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    # Create model(s) and send to device(s)\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    scale = args.hr_image_size // args.lr_image_size\n",
        "    net = MSANet().float()\n",
        "\n",
        "    net.load_state_dict(torch.load(args.model))\n",
        "\n",
        "    if args.distributed:\n",
        "        if args.gpu is not None:\n",
        "            torch.cuda.set_device(args.gpu)\n",
        "            args.batch_size = int(args.batch_size / ngpus_per_node)\n",
        "            args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)\n",
        "\n",
        "            net.cuda(args.gpu)\n",
        "            net = torch.nn.parallel.DistributedDataParallel(net, device_ids=[args.gpu])\n",
        "        else:\n",
        "            net.cuda(args.gpu)\n",
        "            net = torch.nn.parallel.DistributedDataParallel(net)\n",
        "    elif args.gpu is not None:\n",
        "        torch.cuda.set_device(args.gpu)\n",
        "        net.cuda(args.gpu)\n",
        "    else:\n",
        "        net = nn.DataParallel(net).cuda()\n",
        "\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    # Define dataset path and data splits\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    dataset_path = \"Dataset/\"\n",
        "    image_ids_csv = pd.read_csv(dataset_path + \"Image_IDs.csv\")\n",
        "\n",
        "    image_ids = image_ids_csv[\"id\"].values\n",
        "\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    # Create datasets and dataloaders\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    Raman_Dataset_Test = RamanImageDataset(image_ids, dataset_path, batch_size = args.batch_size,\n",
        "                                                    hr_image_size = args.hr_image_size, lr_image_size = args.lr_image_size,\n",
        "                                                    spectrum_len = args.spectrum_len)\n",
        "\n",
        "    test_loader = DataLoader(Raman_Dataset_Test, batch_size = args.batch_size, shuffle = False, num_workers = args.workers)\n",
        "\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    # Evaluate\n",
        "    # ----------------------------------------------------------------------------------------\n",
        "    RCAN_PSNR, Bicubic_PSNR, Nearest_PSNR, RCAN_SSIM, Bicubic_SSIM, Nearest_SSIM, RCAN_MSE, Bicubic_MSE, Nearest_MSE = evaluate(test_loader, net, scale, args)"
      ],
      "metadata": {
        "id": "yqtQlVwwK3GM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Arguments:\n",
        "    pass\n",
        "\n",
        "args = Arguments()\n",
        "args.workers = 0\n",
        "args.batch_size = 1\n",
        "args.spectrum_len = 500\n",
        "args.network = \"MSANet\"\n",
        "args.lr_image_size = 16\n",
        "args.hr_image_size = 64\n",
        "args.spectrum_len = 500\n",
        "args.seed = None\n",
        "args.gpu = 0\n",
        "args.world_size = -1\n",
        "args.rank = -1\n",
        "args.dist_url = \"tcp://224.66.41.62:23456\"\n",
        "args.dist_backend = \"nccl\"\n",
        "args.multiprocessing_distributed = False\n",
        "args.batch_norm = True\n",
        "args.model = \"2024_10_23_adamW_one-cycle-lr_0.00001_MSANet_4.pt\"\n",
        "\n",
        "\n",
        "main_test(args)"
      ],
      "metadata": {
        "id": "I97mxHSasvCS",
        "outputId": "ff61ff67-2c66-4768-c60b-4b1e15bcb2ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0 for testing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-b5b0a68efbd3>:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(args.model))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([1, 500, 64, 64])) that is different to the input size (torch.Size([500, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RCAN PSNR: 15.6709155130409    Bicubic PSNR: 36.48148909128958    Nearest Neighbours PSNR: 35.61135809773206\n",
            "RCAN SSIM: 0.18499248206558513    Bicubic SSIM: 0.7220117542772111    Nearest Neighbours SSIM: 0.6973399780497728\n",
            "RCAN MSE:  0.0022606730926781893    Bicubic MSE:  0.0001601181251598553    Nearest Neighbours MSE:  0.00019475209663152108\n"
          ]
        }
      ]
    }
  ]
}